"How to be evil"
===

_Adapted from "Using data for evil V: The AI Strikes Back" - Duncan Ross & Francine Bennett, Strata Data London 2019
and the book "Weapons of Math Destruction" by Cathy O'Neil._

* Focus on the exciting tech and ignore the consequences of how the resulting model might be used.
* Doing good deliberately is hard
* Doing evil deliberately is hard
* Doing evil accidentally is easy
* Every data scientist has the capability to do good things by thinking about what they're doing, and the capability to do evil by not thinking about what they're doing.

## How to be evil
- You should aim to create a WMD (Weapon of Math Destruction) by concentrating on maximising:
    - Opacity - Make sure you don't try to interpret or understand what your evil model is doing. Don't put a human in the decision loop!
    - Scale - Maximise the number of people that interact with your model.
    - Damage - Ensure there are real-world consequences when your model makes a prediction.
- Stamp out diversity in your teams - they mustn't represent the demographics of the people who will ultimately use or be affected by your models.
- Obtain data in evil ways
  - From children
    - The Home Office asks schools to ask parents to "voluntarily" tell their school the nationality of their children
  - From sick people
    - The NHS gathers lots of data about sick people
  - From kind people
    - Charities might give you data
    - Location data can be just as useful as personal data  
  - From scared people
    - "If you have nothing to hide you shouldn't mind giving us your details"
- Do it at scale
  - Even better, gameify it - in order to compete people will give you more info than they usually would, and they'll encourage others to do the same!
  - e.g. Start a quiz on social media asking friends for their "Evil robot name" - Take your bank sort code, followed by the name of your first pet, then the password for your email account - 101011-CHARLIE-CHANGEME
  - Don't forget to do a "Cambridge Analytica" and harvest their friends' profile data too. This can be handy for profiling people.
  - Smart cities have the potential for pervasive monitoring. Limit oversight of the companies that are using the data.
- Ignore ethics
  - Take advantage of the fact that there exists no widely agreed set of ethical standards for machine learning.
  - Use data as a proxy to infer something else, e.g. inferring that because a person lives in an economically deprived area they are more likely to commit an offence. There may be a correlation, but it isn't causation.
  - Ensure that the model will be used to affect people's life in a significant way, e.g. by deciding whether or not they're allowed to take out finance, or the length of their jail sentence.
  - Deepfakes and language models can help you to generate fake news. 
- Take advantage of as many types of bias as possible: 
  - Great guide at: https://data36.com/statistical-bias-types-explained/
  - Selection bias
  - Self-selection bias
  - Recall bias
  - Observer bias
  - Survivorship bias
  - Omitted variable bias
  - Cause-effect bias
  - Funding bias
  - Cognitive bias
